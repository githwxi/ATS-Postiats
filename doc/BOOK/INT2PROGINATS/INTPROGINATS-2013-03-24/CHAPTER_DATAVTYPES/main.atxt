%{
//
dynload
"libatsdoc/dynloadall.dats"
//
#include "./../proginatsatxt.dats"
//
%}\
#comment("\n\
The file is automatically generated by [atsdoc] from main.atxt.\n\
")
#comment("\n\
Time of Generation: #timestamp()\
")
<chapter id="dataviewtypes">
#title("Dataviewtypes as Linear Datatypes")

#para("\

A dataviewtype can be thought of as a linear version of datatype. To a
large extent, it is a combination of a datatype and a dataview. This
programming feature is primarily introduced into ATS for the purpose of
providing the kind convenience of pattern matching associated with
datatypes while incurring no need for run-time garbage collection (GC). In
a situation where GC must be reduced or even completely eliminated,
dataviewtypes can often chosen as a replacement for datatypes.  I now
present in this chapter some commonly encountered dataviewtypes and their
uses.

")

<sect1
id="linear_optional_values">
#title("Linear Optional Values")

#para("\

When an optional value is created, it is most likely to be used immediately
and then discarded. If such a value is assigned a linear type, then the
memory allocated for storing it can be efficiently reclaimed.  The
dataviewtype #code("option_vt") for linear optional values is declared as
follows:

")

#atscode('\
dataviewtye
option_vt (a:t@ype+, bool) =
  | Some_vt (a, true) of a | None_vt (a, false) of ()
// end of [option_vt]

viewtypedef
Option_vt (a:t@ype) = [b:bool] option_vt (a, b)
')

#para('\

By the declaration, the dataviewtype #code("option_vt") is covariant in its
first argument and there are two data constructors #code("Some_vt") and
#code("None_vt") associated with it. In the following example,
#code("find_rightmost") tries to find the rightmost element in a list that
satisfies a given predicate:

')

#atscode('\
fun{a:t@ype}
find_rightmost {n:nat} .<n>.
  (xs: list (a, n), P: (a) -<cloref> bool): Option_vt (a) =
  case+ xs of
  | list_cons (x, xs) => let
      val opt = find_rightmost (xs, P)
    in
      case opt of
      | ~None_vt () => if P (x) then Some_vt (x) else None_vt ()
      | _ => opt
    end // end of [list_cons]
  | list_nil () => None_vt ()
// end of [find_rightmost]
')

#para('\

Note that the tilde symbol (#code("~")) in front of the pattern
#code("None_vt()") indicates that the memory for the node that matches the
pattern is freed before the body of the matched clause is evaluated.  In
this case, no memory is actually freed as #code("None_vt") is mapped to the
null pointer.  I will soon give more detailed explanation about freeing
memory allocated for constructors associated with dataviewtypes.

')

#para("\

As another example, the following function template #code("list_optcons")
tries to construct a new list with its head element extracted from a given
optional value:

")

#atscode('\
fn{a:t@ype}
list_optcons {b:bool} {n:nat} (
  opt: option_vt (a, b), xs: list (a, n)
) : list (a, n+int_of_bool(b)) =
  case+ opt of
  | ~Some_vt (x) => list_cons (x, xs) | ~None_vt () => xs
// end of [list_optcons]
')

#para('\

The symbol #code("int_of_bool") stands for a built-in static function in
ATS that maps #code("true") and #code("false") to 1 and 0,
respectively. What is special here is that the first argument of
#code("list_optcons"), which is linear, is consumed after a call to
#code("list_optcons") returns and the memory it occupies is reclaimed.

')

</sect1>#comment("sect1/id=linear_optional_values")

<sect1 id="linear_lists">
#title("Linear Lists")

#para('\

A linear list is essentially the same as a singly-linked list depicted by
the dataview #code("sllst_v"). However, memory allocation and deallocation
of list nodes that were not handled previously are handled this time.  The
following declaration introduces a dataviewtype #code("list_vt"), which
forms a boxed type (of the sort #code("viewtype")) when applied to a type
and an integer:

')

#atscode('\
dataviewtype
list_vt (a:t@ype+, int) =
  | {n:nat}
    list_vt_cons (a, n+1) of (a, list_vt (a, n))
  | list_vt_nil (a, 0) of ()
// end of [list_vt]
')

#para('\

Assume that a data constructor named #emph("foo") is associated with a
dataviewtype.  Then there is a viewtype construtor of the name
#emph("foo_unfold") that takes n addresses to form a viewtype, where n is
the arity of #emph("foo"). For instance, there is a viewtype constructor
#code("list_vt_cons_unfold") that takes two address L0 and L1 to form a
viewtype #code("list_vt_cons_unfold")(L0, L1). This viewtype is for a list
node created by a call to #code("list_vt_cons") such that the two arguments
of #code("list_vt_cons") are located at L0 and L1 while the proofs for the
at-views associated with L0 and L1 are put in the store for currently
available proofs.

')

#para('\

Given a type T and an integer I, the viewtype #code("list_vt")(T, I) is for
linear lists of length I in which each element is assigned the type T.  The
following function template #code("length") computes the length of a given
linear list:

')

#atscode('\
fn{a:t@ype}
length {n:nat}
  (xs: !list_vt (a, n)): int n = let
  fun loop
    {i,j:nat | i+j==n} .<i>.
    (xs: !list_vt (a, i), j: int j): int (n) =
    case+ xs of
    | list_vt_cons (_, !p_xs1) => let
        val n = loop (!p_xs1, j+1); val () = fold@ (xs) in n
      end // end of [list_vt_cons]
    | list_vt_nil () => (fold@ (xs); j)
  // end of [loop]
in
  loop (xs, 0)
end // end of [length]
')

#para('\

The interface of #code("length") indicates that #code("length")&lt;T&gt;
returns an integer equal to I when applied to a list of the type
#code("list_vt")(T, I), where T and I are a type and an integer,
respectively. Note that the symbol #code("!") in front of the type of a
function argument indicates that the argument is call-by-value and it is
preserved after a call to the function.

')

#para('\

What is particularly interesting here is the way in which pattern matching
on a value of a dataviewtype works. In the body of the inner function
#code("loop"), the type of #code("xs") changes to
#code("list_vt_cons_unfold")(L1, L2) for some addresses L1 and L2 when it
matches the pattern #code("list_vt_cons(_, !p_xs1)"), and #code("p_xs1") is
bound to a value of the type #code("ptr")(L2), and a proof of the at-view
#code("a")@L1 and another proof of the at-view #code("list_vt(a,n-1)")@L2
are automatically put into the store for the currently availble
proofs. Note that the symbol #code("!") in front of the variable
#code("p_xs1") indicates that #code("p_xs1") is bound to the pointer to the
tail of the list referred to by #code("xs1") (rather than the tail itself).
In order to change the type of #code("xs") back to the type
#code("list_vt(a, n)"), we can apply #code("fold@") to #code("xs") and this
application implicitly consumes a proof of the at-view #code("a")@L1 and
another proof of the at-view #code("list_vt(a, n-1)")@L2. Note that
#code("fold@") is a keyword in ATS, and an application of #code("fold@") is
treated as a proof and it is erased after typechecking.

In the case where #code("xs") matches the pattern #code("list_vt_nil()"),
the type of #code("xs") changes into #code("list_vt_nil()") while there is
no proof added to the store for the currently available proofs, and the
type of #code("xs") restores to #code("list_vt(a, 0)") when
#code("fold@") is applied to it.

')

#para('\

Let us now see an example involving a linear list being freed manually:

')

#atscode('\
fun{a:t@ype}
list_vt_free
  {n:nat} .<n>. (xs: list_vt (a, n)): void =
  case+ xs of
  | ~list_vt_cons (x, xs1) => list_vt_free (xs1) // [x] can be replaced with [_]
  | ~list_vt_nil () => ()
// end of [list_vt_free]
')

#para('\

In the case where #code("xs") matches the pattern #code("list_vt_cons(x,
xs1)"), the names #code("x") and #code("xs1") are bound to the head and the
tail of the list referred to by #code("xs"), respectively, and the type of
#code("xs") changes to #code("list_vt_cons")(L1, L2) for some addresses
while a proof of the at-view #code("a")@L1 and another proof of the at-view
#code("list_vt(a, n-1)?!")@L2 are put into the store for currently
available proofs. Note that the symbol #code("?!") indicates that the tail
of the list, which is linear, is already taken out (as it is now referred
by #code("xs1")).  The special symbol #code("~") in front of the pattern
#code("list_vt_cons(x, xs1)") indicates that the list node referred to
by #code("xs") after #code("xs") matches the pattern is freed immediately.

')

#para('\

It is also possible to use the special function #code("free@") to
explicitly free a node (also called a skeleton) left in a linear variable
after the variable matches a pattern formed with a constructor associated
with a dataviewtypes. For instance, the following code gives another
implementation of #code("list_vt_free"):

')

#atscode('\
fun{a:t@ype}
list_vt_free
  {n:nat} .<n>. (xs: list_vt (a, n)): void =
  case+ xs of
  | list_vt_cons (x, xs1) => (free@ {a}{0} (xs); list_vt_free (xs1))
  | list_vt_nil () => free@ {a} (xs)
// end of [list_vt_free]
')

#para('\

As using #code("free@") is a bit tricky in practice, I present more details
as follows. First, let us note that the constructors #code("list_vt_nil")
and #code("list_vt_cons") associated with #code("list_vt") are assigned the
following types:

')

#atscode('\
list_vt_nil : // one quantifier
  {a:t@ype} () -> list_vt (a, 0)
list_vt_cons : // two quantifiers
  {a:t@ype} {n:nat} (a, list_vt (a, n)) -> list_vt (a, n+1)
')

#para('\

If #code("free@") is applied to a node of the type #code("list_vt_nil")(),
it needs one static argument. which is a type, to instantiate the
quantifier in the type of the constructor #code("list_vt_nil"). If
#code("free@") is applied to a node of the type
#code("list_vt_cons_unfold")(L1, L2), then it needs two static arguments,
which are a type and an integer, to instantiate the two quantifiers in the
type of the constructor #code("list_vt_cons"). In the case where the type
of #code("xs") is #code("list_vt_cons_unfold")(L1, L2), typechecking the
call #code("free@ {a}{0} (xs)") implicitly consumes a proof of the at-view
#code("a?")@L1 and another proof of the at-view #code("list_vt(a, 0)?").
As there is no difference between #code("list_vt")(T, 0)? and
#code("list_vt")(T, I)? for any T and I, the static argument 0 is supplied
here. As a matter of fact, any natural number can be used in place of 0 as
the second static argument of #code("free@").

')

#para('\

The next example I present is a function template that turns a linear list into
its reverse:

')

#atscode('\
fn{a:t@ype}
reverse {n:nat}
  (xs: list_vt (a, n)): list_vt (a, n) = let
  fun revapp
    {i,j:nat | i+j==n} .<i>.
    (xs: list_vt (a, i), ys: list_vt (a, j)): list_vt (a, n) =
    case+ xs of
    | list_vt_cons (_, !p_xs1) => let
        val xs1 = !p_xs1; val () = !p_xs1 := ys; val () = fold@ (xs)
      in
        revapp (xs1, xs)
      end // end of [list_vt_cons]
    | ~list_vt_nil () => ys
  // end of [revapp]
in
  revapp (xs, list_vt_nil)
end // end of [reverse]
')

#para('\

This implementation of list reversal directly corresponds to the one
presented previously that is based the dataview #code("slseg_v") (for
singly-linked list segments). Comparing the two implementations, we can see
that the above one is significantly simplified at the level of types. For
instance, there is no explicit mentioning of pointers in the types assigned
to #code("reverse") and #code("revapp").

')

#para('\

The following implementation of list append makes use of the feature
of call-by-reference:

')

#atscode('\
fn{a:t@ype}
append {m,n:nat} (
  xs: list_vt (a, m), ys: list_vt (a, n)
) : list_vt (a, m+n) = let
  fun loop {m,n:nat} .<m>. // [loop] is tail-recursive
    (xs: &list_vt (a, m) >> list_vt (a, m+n), ys: list_vt (a, n)): void =
    case+ xs of
    | list_vt_cons (_, !p_xs1) => let
        val () = loop (!p_xs1, ys) in fold@ (xs)
      end // end of [list_vt_cons]
    | ~list_vt_nil () => xs := ys // [xs] is a left-value
  // end of [loop]
  var xs: List_vt (a) = xs // creating a left-value for [xs]
  val () = loop (xs, ys)
in
  xs
end // end of [append]
')

#para('\

As the call #code("fold@(xs)") in the body of the function #code("loop") is
erased after typechecking, #code("loop") is a tail-recursive function.
Therefore, #code("append") can be called on lists of any length without the
concern of possible stack overflow. The type for the first argument of
#code("loop") begins with the symbol #code("&amp;"), which indicates that
this argument is call-by-reference. The type of #code("loop") simply means
that its first argument is changed from a list of length m into a list of
length m+n while its second argument is consumed.

Again, this implementation of list append essentially corresponds to the
one presented previously that is based on the dataview #code("slseg_v").
Comparing these two, we can easily see that the above one is much simpler
and cleaner, demonstrating concretely some advantage of dataviewtypes over
dataviews.

')

#para('\

Lastly in this section, I mention a closely related issue involving
(functional) list construction and tail-recursion. Following is a typical
implementation of functioal list concatenation:

')

#atscode('\
fun{a:t@ype}
append1 {m,n:nat}
  (xs: list (a, m), ys: list (a, n)): list (a, m+n) =
  case+ xs of
  | list_cons (x, xs) => list_cons (x, append1 (xs, ys))
  | list_nil () => ys
// end of [append1]
')

#para('\

Clearly, #code("append1") is not tail-recursive, which means that it may
cause stack overflow at run-time if its first argument is very long (e.g.,
containing 1 million elements). There is, however, a direct and type-safe
way in ATS to implement functional list concatenation in a tail-recursive
manner, thus eliminating the concern of potential stack overflow. For
instance, the following implementation of #code("append2") returns the
concatenation of two given lists while being tail-recursive:

')

#atscode('\
fun{a:t@ype}
append2 {m,n:nat} (
  xs: list (a, m)
, ys: list (a, n)
) : list (a, m+n) = let
  fun loop
    {m,n:nat} .<m>. (
    xs: list (a, m)
  , ys: list (a, n)
  , res: &(List a)? >> list (a, m+n)
  ) :<> void = begin case+ xs of
    | list_cons (x, xs) => let
        val () = (
          res := list_cons {a}{0} (x, ?) // a partially initialized list
        ) // end of [val]
        val+ list_cons (_, !p) = res // [p] points to the tail of the list
        val () = loop (xs, ys, !p)
      in
        fold@ res // this is a no-op at run-time
      end // end of [list_cons]
    | list_nil () => (res := ys)
  end // end of [loop]
  var res: List a // uninitialized variable
  val () = loop (xs, ys, res)
in
  res
end // end of [append2]
')

#para('\

During typechecking, the expression #code("list_cons {a}{0} (x, ?)"), is
assigned the (linear) type #code("list_cons")(L1, L2) for some addresses L1
and L2 while a proof of the at-view #code("a")@L1 and another proof of the
at-view #code("list(a, 0)?")@L2 are put into the store for the currently
available proofs. Note that the special symbol #code("?") here simply
indicates that the tail of the newly constructed list is uninitialized. A
partially initialized list of the type #code("list_cons")(L1, L2) is
guaranteed to match the pattern #code("list_cons(_, !p)"), yielding a
bindng between #code("p") and the (possibly uninitialized) tail of the
list. When #code("fold@") is called on a variable of the type
#code("list_cons")(L1, L2), it changes the type of the variable to
#code("list")(T, N+1) by consuming a proof of the view T@L1 and another
proof of the view #code("list")(T, N), where T and N are a type and an
integer, respectively.

')

#para('\

In summary, dataviewtypes can largely retain the convenience of pattern
matching associated with datatypes while requiring no GC support at
run-time.  Compared to dataviews, dataviewtypes are less general. However,
if a dataviewtype can be employed to solve a problem, then the solution is
often significantly simpler and cleaner than an alternative dataview-based
one.

')

</sect1>#comment("sect1/id=linear_lists")

#comment(" ****** ****** ")

<sect1 id="example_mergesort_lin">
#title("Example: Mergesort on Linear Lists")

#para("\

When mergesort is employed to sort an array of elements, it requires
additional memory proportionate to the size of the array in order to move
the elements around, which is considered a significant weakness of
mergesort. However, mergesort does not have this requirement when it
operates on a linear list.  I present as follows an implementation of
mergesort on linear lists that can readily rival its counterpart in C in
terms of time-efficiency as well as memory-efficiency. The invariants
captured in this implementation and the easiness to capture them should
provide strong evidence to ATS being a programming language
capable of enforcing great precision in practical programming.

")

#para('\

First, let us introduce a type definition and an interface for a function
template (for comparing elements in a list to be sorted):

')

#atscode('\
typedef cmp (a:t@ype) = (&a, &a) -> int

extern
fun{a:t@ype} compare (x: &a, y: &a, cmp: cmp (a)): int
')

#para('\

The interface for mergesort is given as follows:

')

#atscode('\
extern
fun{a:t@ype}
mergesort {n:nat}
  (xs: list_vt (a, n), cmp: cmp a): list_vt (a, n)
// end of [mergesort]
')

#para('\

The first argument of #code("mergesort") is a linear list (to be sorted)
and the second one a function for comparing the elements in the linear
list.  Clearly, the interface of #code("mergesort") indicates that
#code("mergesort") consumes its first argument and then returns a linear
list that is of same length as its first argument. As is to become clear,
the returned linear list is constructed with the nodes of the consumed
one. In particular, the implementation of mergesort given here does not
involve any memory allocation or deallocation.

')

#para('\

The function template for merging two sorted lists into one is given as follows:
')

#atscode('\
fun{a:t@ype}
merge // tail-rec
  {m,n:nat} .<m+n>. (
  xs: list_vt (a, m)
, ys: list_vt (a, n)
, res: &List_vt(a)? >> list_vt (a, m+n)
, cmp: cmp a
) : void =
  case+ xs of
  | list_vt_cons (!p_x, !p_xs1) => (
    case+ ys of
    | list_vt_cons (!p_y, !p_ys1) => let
        val sgn = compare<a> (!p_x, !p_y, cmp)
      in
        if sgn <= 0 then let // stable sorting
          val () = res := xs
          val xs1 = !p_xs1
          val () = fold@ (ys)
          val () = merge (xs1, ys, !p_xs1, cmp)
        in
          fold@ (res)
        end else let
          val () = res := ys
          val ys1 = !p_ys1
          val () = fold@ (xs)
          val () = merge (xs, ys1, !p_ys1, cmp)
        in
          fold@ (res)
        end // end of [if]
      end (* end of [list_vt_cons] *)
    | ~list_vt_nil () => (fold@ (xs); res := xs)
    ) // end of [list_vt_cons]
  | ~list_vt_nil () => (res := ys)
// end of [merge]
')

#para('\

Unlike the one given in a previous functional implementation, this
implementation of #code("merge") is tail-recursive and thus is guaranteed
to be translated into a loop in C by the ATS compiler. This means that the
concern of #code("merge") being unable to handle very long lists (e.g.,
containg 1 million elements) due to potential stack overflow is completely
eliminated.

')

#para('\

The next function template is for splitting a given linear lists into two:

')

#atscode('\
fun{a:t@ype}
split {n,k:nat | k <= n} .<n-k>. (
  xs: &list_vt (a, n) >> list_vt (a, n-k), nk: int (n-k)
) : list_vt (a, k) =
  if nk > 0 then let
    val+ list_vt_cons (_, !p_xs1) = xs
    val res = split (!p_xs1, nk-1); val () = fold@ (xs)
  in
    res
  end else let
    val res = xs; val () = xs := list_vt_nil () in res
  end // end of [if]
// end of [split]
')

#para('\

Note that the implementation of #code("split") is also tail-recursive.

')

#para('\

The following function template #code("msort") takes a linear list, its
length and a comparsion function, and it returns a sorted version of the
given linear list:

')

#atscode('\
fun{a:t@ype}
msort {n:nat} .<n>. (
  xs: list_vt (a, n), n: int n, cmp: cmp(a)
) : list_vt (a, n) =
  if n >= 2 then let
    val n2 = n / 2
    val n3 = n - n2
    var xs = xs // a left-value for [xs]
    val ys = split {n,n/2} (xs(*cbr*), n3) // xs: call-by-ref
    val xs = msort (xs, n3, cmp)
    val ys = msort (ys, n2, cmp)
    var res: List_vt (a)
    val () = merge (xs, ys, res(*cbr*), cmp) // xs: call-by-ref
  in
    res
  end else xs
// end of [msort]
')

#para('\

The second argument of #code("msort") is passed so that the length of the
list being sorted does not have to be computed directly by traversing the
list when each recursive call to #code("msort") is made.

')

#para('\

Finally, #code("mergesort") can be implemented with a call to
#code("msort"):

')

#atscode('\
implement{a}
mergesort (xs, cmp) = msort (xs, length (xs), cmp)
')

#para("\

Please find the entire code in this section plus some additional
code for testing #mycodelink("CHAPTER_DATAVTYPES/mergesort.dats", "on-line").

")

</sect1>#comment("sect1/id=example_mergesort_lin")

#comment(" ****** ****** ")

<sect1 id="linear_binary_search_trees">
#title("Linear Binary Search Trees")

#para("\

A binary search tree with respect to a given ordering is a binary tree such
that the value stored in each node inside the tree is greater than or equal
to those stored in the left child of the node and less than or equal to
those stored in the right child of the node.  Binary search trees are a
common data structure for implementing finite maps.

")

#para("\

A family of binary
trees are said to be balanced if there is a fixed constant C (for the
entire family) such that the ratio between the length of a longest path and
the length of a shortest path is bounded by C for every tree in the
family. For instance, common examples of balanced binary trees include AVL
trees and red-black trees. Finite maps based on balanced binary search
trees support guaranteed log-time insertion and deletion operations, that
is, the time to complete such an operation is O(log(n)) in the worst case,
where n is the size of the map.

")

#para('\

In this section, I am to implement several basic operations on linear
binary search trees, further illustrating some use of dataviewtypes. Let us
first declare as follows a dataviewtype #code("bstree_vt") for linear
binary (search) trees:

')

#atscode('\
dataviewtype
bstree_vt
  (a:t@ype+, int) =
  | {n1,n2:nat}
    bstree_vt_cons (a, 1+n1+n2) of
      (bstree_vt (a, n1), a, bstree_vt (a, n2))
  | bstree_vt_nil (a, 0) of ()
// end of [bstree_vt]
')

#para('\

Note that the integer index of #code("bstree_vt") captures the size
information of a binary (search) tree.  There are two constructors
#code("bstree_vt_cons") and #code("bstree_vt_nil") associated with
#code("bstree_vt"). It should be pointed out that the tree created by
#code("bstree_vt_nil") is empty and thus not a leaf, which on the other
hand is a node whose left and right children are both empty.  As a simple
example, the following function template #code("size") computes the size of
a given tree:

')

#atscode('\
fun{a:t@ype}
size {n:nat} .<n>. (
  t: !bstree_vt (a, n)
) : int (n) =
  case+ t of
  | bstree_vt_cons (!p_tl, _, !p_tr) => let
      val n = 1 + size (!p_tl) + size (!p_tr) in fold@ (t); n
    end // end of [bstree_vt_cons]
  | bstree_vt_nil () => (fold@ (t); 0)
// end of [size]
')

#para('\

Assume that we have a binary search tree with repect to some ordering.  If
a predicate P on the elements stored in the tree possesses the property
that P(x1) implies P(x2) whenever x1 is less than x2 (according to the
ordering), then we can locate the least element in the tree that satisfies
the predicate P by employing so-called binary search as is demonstrated in
the following implementation of #code("search"):

')

#atscode('\
fun{a:t@ype}
search {n:nat} .<n>. (
  t: !bstree_vt (a, n), P: (&a) -<cloref> bool
) : Option_vt (a) =
  case+ t of
  | bstree_vt_cons
      (!p_tl, !p_x, !p_tr) =>
      if P (!p_x) then let
        val res = search (!p_tl, P)
        val res = (
          case+ res of
          | ~None_vt () => Some_vt (!p_x) | _ => res
        ) : Option_vt (a)
      in
        fold@ (t); res
      end else let
        val res = search (!p_tr, P) in fold@ (t); res
      end // end of [if]
  | bstree_vt_nil () => (fold@ (t); None_vt ())
// end of [search]
')

#para('\

Clearly, if the argument #code("t") of #code("search") ranges over a family
of balanced trees, then the time-complexity of #code("search") is O(log(n))
(assuming that #code("P") is O(1)).

')

#para('\

Let us next see an operation that inserts a given element into a binary
search tree:

')

#atscode('\
fun{a:t@ype}
insert {n:nat} .<n>. (
  t: bstree_vt (a, n), x0: &a, cmp: cmp(a)
) : bstree_vt (a, n+1) =
  case+ t of
  | bstree_vt_cons
      (!p_tl, !p_x, !p_tr) => let
      val sgn = compare<a> (x0, !p_x, cmp)
    in
      if sgn <= 0 then let
        val () = !p_tl := insert (!p_tl, x0, cmp)
      in
        fold@ (t); t
      end else let
        val () = !p_tr := insert (!p_tr, x0, cmp)
      in
        fold@ (t); t
      end (* end of [if] *)
    end // end of [bstree_vt_cons]
  | ~bstree_vt_nil () =>
      bstree_vt_cons (bstree_vt_nil, x0, bstree_vt_nil)
    // end of [bstree_vt_nil]
// end of [insert]
')

#para('\

When inserting an element, the function template #code("insert") extends
the given tree with a new leaf node containing the element, and this form
of insertion is often referred to as leaf-insertion.  There is another form
of insertion often referred to as root-insertion, which always puts at the
root position the new node containing the inserted element. The following
function template #code("insertRT") is implemented to perform a standard
root-insertion operation:

')

#atscode('\
fun{a:t@ype}
insertRT {n:nat} .<n>. (
  t: bstree_vt (a, n), x0: &a, cmp: cmp(a)
) : bstree_vt (a, n+1) =
  case+ t of
  | bstree_vt_cons
      (!p_tl, !p_x, !p_tr) => let
      val sgn = compare<a> (x0, !p_x, cmp)
    in
      if sgn <= 0 then let
        val tl = insertRT (!p_tl, x0, cmp)
        val+ bstree_vt_cons (_, !p_tll, !p_tlr) = tl
        val () = !p_tl := !p_tlr
        val () = fold@ (t)
        val () = !p_tlr := t
      in
        fold@ (tl); tl
      end else let
        val tr = insertRT (!p_tr, x0, cmp)
        val+ bstree_vt_cons (!p_trl, _, !p_trr) = tr
        val () = !p_tr := !p_trl
        val () = fold@ (t)
        val () = !p_trl := t
      in
        fold@ (tr); tr
      end
    end // end of [bstree_vt_cons]
  | ~bstree_vt_nil () =>
      bstree_vt_cons (bstree_vt_nil, x0, bstree_vt_nil)
    // end of [bstree_vt_nil]
// end of [insertRT]
')

#para('\

The code immediately following the first recursive call to
#code("insertRT") performs a right tree rotation. Let us use T(tl, x, tr)
for a tree such that its root node contains the element x and its left and
right children are tl and tr, respectively. Then a right rotation turns
T(T(tll, xl, tlr), x, tr) into T(tll, xl, T(tlr, x, tr)).
The code immediately following the second recursive call to
#code("insertRT") performs a left tree rotation, which turns
T(tl, x, T(trl, xr, trr)) into T(T(tl, x, tlr), xr, trr).

')

#para('\

To further illustrate tree rotations, I present as follows
two function templates #code("lrotate") and #code("rrotate"), which
implement the left and right tree rotations, respectively:

')

#atscode('\
fn{a:t@ype}
lrotate
  {nl,nr:nat | nr > 0}
  {l_tl,l_x,l_tr:addr} (
  pf_tl: bstree_vt (a, nl) @ l_tl
, pf_x: a @ l_x
, pf_tr: bstree_vt (a, nr) @ l_tr
| t: bstree_vt_cons_unfold (l_tl, l_x, l_tr)
, p_tl: ptr l_tl
, p_tr: ptr l_tr
) : bstree_vt (a, 1+nl+nr) = let
  val tr = !p_tr
  val+ bstree_vt_cons (!p_trl, _, !p_trr) = tr
  val () = !p_tr := !p_trl
  val () = fold@ (t)
  val () = !p_trl := t
in
  fold@ (tr); tr
end // end of [lrotate]

fn{a:t@ype}
rrotate
  {nl,nr:nat | nl > 0}
  {l_tl,l_x,l_tr:addr} (
  pf_tl: bstree_vt (a, nl) @ l_tl
, pf_x: a @ l_x
, pf_tr: bstree_vt (a, nr) @ l_tr
| t: bstree_vt_cons_unfold (l_tl, l_x, l_tr)
, p_tl: ptr l_tl
, p_tr: ptr l_tr
) : bstree_vt (a, 1+nl+nr) = let
  val tl = !p_tl
  val+ bstree_vt_cons (!p_tll, x, !p_tlr) = tl
  val () = !p_tl := !p_tlr
  val () = fold@ (t)
  val () = !p_tlr := t
in
  fold@ (tl); tl
end // end of [rrotate]
')

#para('\

Given three addresses L0, L1 and L2, the type
#code("bstree_vt_cons_unfold")(L0, L1, l2) is for a tree node created
by a call to #code("bstree_vt_cons") such that the three arguments of
#code("bstree_vt_cons") are located at L0, L1 and L2, and the proofs for the
at-views associated with L0, L1 and L2 are put in the store for the currently
available proofs.

')

#para('\

The function template #code("insertRT") for root-insertion can now be
implemented as follows by making direct use of #code("lrotate") and
#code("rrotate"):

')

#atscode('\
fun{a:t@ype}
insertRT {n:nat} .<n>. (
  t: bstree_vt (a, n), x0: &a, cmp: cmp(a)
) : bstree_vt (a, n+1) =
  case+ t of
  | bstree_vt_cons
      (!p_tl, !p_x, !p_tr) => let
      val sgn = compare<a> (x0, !p_x, cmp)
    in
      if sgn <= 0 then let
        val () = !p_tl := insertRT (!p_tl, x0, cmp)
      in
        rrotate (view@(!p_tl), view@(!p_x), view@(!p_tr) | t, p_tl, p_tr)
      end else let
        val () = !p_tr := insertRT (!p_tr, x0, cmp)
      in
        lrotate (view@(!p_tl), view@(!p_x), view@(!p_tr) | t, p_tl, p_tr)
      end
    end // end of [bstree_vt_cons]
  | ~bstree_vt_nil () =>
      bstree_vt_cons (bstree_vt_nil, x0, bstree_vt_nil)
    // end of [bstree_vt_nil]
// end of [insertRT]
')

#para('\

I would like to point out that neither #code("insert") nor
#code("insertRT") is tail-recursive. While it is straightforward to give
the former a tail-recursive implementation, there is no direct way to do
the same to the latter. In order to implement root-insertion in a
tail-recursive manner, we are in need of binary search trees with parental
pointers (so as to allow each node to gain direct access to its parent),
which can be done with dataviews but not with dataviewtypes.

')

#para("\

Please find the entire code in this section plus some additional
code for testing #mycodelink("CHAPTER_DATAVTYPES/bstree_vt.dats", "on-line").

")

</sect1>#comment("sect1/id=linear_binary_search_trees")

<sect1
id="transition_from_datatypes_to_dataviewtypes">
#title("Transition from Datatypes to Dataviewtypes")

#para('\

Many programmers are likely to find it a rather involved task to write code
manipulating values of dataviewtypes. When handling a complex data
structure, I myself often try to first use a datatype to model the data
structure and implement some functionalities of the data structure based
the datatype. I then change the datatype into a corresponding dataviewtype
and modify the implementation accordingly to make it work with the
dataviewtype. I now present as follows an implementation of linear
red-black trees that is directly based on a previous
<xref linkend="example_fun_red-black_trees"/>,
illustrating concretely a kind of gradual transition from datatypes to
dataviewtypes that can greatly reduce the level of difficulty one may
otherwise encounter in an attempt to program with dataviewtypes directly.

')

#para('\

The following declaration of dataviewtype #code("rbtree") is identical to
the previous declaration of datatype #code("rbtree") except the keyword
#code("dataviewtype") being now used instead of the keyword #code("datatype"):

')

#atscode('\
\#define BLK 0; \#define RED 1
sortdef clr = {c:int | 0 <= c; c <= 1}

dataviewtype
rbtree (
  a: t@ype, int(*c*), int(*bh*), int(*v*)
) = // element type, color, black height, violations
  | rbtree_nil (a, BLK, 0, 0) of ()
  | {c,cl,cr:clr} {bh:nat} {v:int}
      {c==BLK && v==0 || c == RED && v==cl+cr}
    rbtree_cons (a, c, bh+1-c, v) of (
      int c, rbtree0 (a, cl, bh), a, rbtree0 (a, cr, bh)
    ) // end of [rbtree_cons]
// end of [rbtree]

where rbtree0 (a:t@ype, c:int, bh:int) = rbtree (a, c, bh, 0)
')

#para('\

At the first sight, the following function template #code("insfix_l") is
greatly more involved that a previous version of the same name (for
manipulating functional red-black trees):

')

#atscode('\
fn{a:t@ype}
insfix_l // right rotation
  {cl,cr:clr}
  {bh:nat}
  {v:nat}
  {l_c,l_tl,l_x,l_tr:addr} (
  pf_c: int(BLK) @ l_c
, pf_tl: rbtree (a, cl, bh, v) @ l_tl
, pf_x: a @ l_x
, pf_tr: rbtree (a, cr, bh, 0) @ l_tr
| t: rbtree_cons_unfold (l_c, l_tl, l_x, l_tr)
, p_tl: ptr (l_tl)
) : [c:clr] rbtree0 (a, c, bh+1) = let
  \#define B BLK
  \#define R RED
  \#define cons rbtree_cons
in
  case+ !p_tl of
  | cons (!p_cl as R, !p_tll as cons (!p_cll as R, _, _, _), _, !p_tlr) => let
//
      val () = !p_cll := B
      val () = fold@ (!p_tll)
//
      val tl = !p_tl
      val () = !p_tl := !p_tlr
      val () = fold@ (t)
//
      val () = !p_tlr := t
    in
      fold@ (tl); tl
    end // end of [cons (R, cons (R, ...), ...)]
  | cons (!p_cl as R, !p_tll, _, !p_tlr as cons (!p_clr as R, !p_tlrl, _, !p_tlrr)) => let
//
      val tl = !p_tl
      val () = !p_tl := !p_tlrr
      val () = fold@ (t)
      val () = !p_tlrr := t
//
      val tlr = !p_tlr
      val () = !p_tlr := !p_tlrl
      val () = !p_cl := B
      val () = fold@ (tl)
      val () = !p_tlrl := tl
//
    in
      fold@ (tlr); tlr
    end // end of [cons (R, ..., cons (R, ...))]
  | _ =>> (fold@ (t); t)
end // end of [insfix_l]
')

#para('\

However, I would like to point out that the interface for the above
#code("insfix_l") is a #emph("direct") translation of the interface for the
previous #code("infix_l"). In other words, the previously captured relation
between a tree being rotated and the one obtained from applying
#code("infix_l") to it also holds in the setting of linear red-black trees.
The very same statement can be made about the following function template
#code("insfix_r"), which is precisely a mirror image of #code("insfix_l"):

')

#atscode('\
fn{a:t@ype}
insfix_r // left rotation
  {cl,cr:clr}
  {bh:nat}
  {v:nat}
  {l_c,l_tl,l_x,l_tr:addr} (
  pf_c: int(BLK) @ l_c
, pf_tl: rbtree (a, cl, bh, 0) @ l_tl
, pf_x: a @ l_x
, pf_tr: rbtree (a, cr, bh, v) @ l_tr
| t: rbtree_cons_unfold (l_c, l_tl, l_x, l_tr)
, p_tr: ptr (l_tr)
) : [c:clr] rbtree0 (a, c, bh+1) = let
  \#define B BLK
  \#define R RED
  \#define cons rbtree_cons
in
  case+ !p_tr of
  | cons (!p_cr as R, !p_trl, _, !p_trr as cons (!p_crr as R, _, _, _)) => let
//
      val () = !p_crr := B
      val () = fold@ (!p_trr)
//
      val tr = !p_tr
      val () = !p_tr := !p_trl
      val () = fold@ (t)
//
      val () = !p_trl := t
    in
      fold@ (tr); tr
    end // end of [cons (R, ..., cons (R, ...))]
  | cons (!p_cr as R, !p_trl as cons (!p_crr as R, !p_trll, _, !p_trlr), _, !p_trr) => let
//
      val tr = !p_tr
      val () = !p_tr := !p_trll
      val () = fold@ (t)
      val () = !p_trll := t
//
      val trl = !p_trl
      val () = !p_trl := !p_trlr
      val () = !p_cr := B
      val () = fold@ (tr)
      val () = !p_trlr := tr
//
    in
      fold@ (trl); trl
    end // end of [cons (R, cons (R, ...), ...)]
  | _ =>> (fold@ (t); t)
end // end of [insfix_r]
')

#para('\

As can be expected,
the following function template #code("rbtree_insert") is essentially a
direct translation of the one of the same name for inserting an element
into a functional red-black tree:

')

#atscode('\
extern
fun{a:t@ype}
rbtree_insert
  {c:clr} {bh:nat} (
  t: rbtree0 (a, c, bh), x0: &a, cmp: cmp a
) : [bh1:nat] rbtree0 (a, BLK, bh1)

implement{a}
rbtree_insert
  (t, x0, cmp) = let
//
\#define B BLK; \#define R RED
\#define nil rbtree_nil; \#define cons rbtree_cons
//
fun ins
  {c:clr} {bh:nat} .<bh,c>. (
  t: rbtree0 (a, c, bh), x0: &a
) :<cloref1> [cl:clr; v:nat | v <= c] rbtree (a, cl, bh, v) =
  case+ t of
  | cons (
      !p_c, !p_tl, !p_x, !p_tr
    ) => let
      val sgn = compare<a> (x0, !p_x, cmp)
    in
      if sgn < 0 then let
        val [cl,v:int] tl = ins (!p_tl, x0)
        val () = !p_tl := tl
      in
        if !p_c = B then
          insfix_l (view@(!p_c), view@(!p_tl), view@(!p_x), view@(!p_tr) | t, p_tl)
        else let
          val () = !p_c := R in fold@ {a}{..}{..}{cl} (t); t
        end // end of [if]
      end else if sgn > 0 then let
        val [cr,v:int] tr = ins (!p_tr, x0)
        val () = !p_tr := tr
      in
        if !p_c = B then
          insfix_r (view@(!p_c), view@(!p_tl), view@(!p_x), view@(!p_tr) | t, p_tr)
        else let
          val () = !p_c := R in fold@ {a}{..}{..}{cr} (t); t
        end // end of [if]
      end else (fold@ {a}{..}{..}{0} (t); t) // end of [if]
    end // end of [cons]
  | ~nil () => cons {..}{..}{..}{0} (R, nil, x0, nil)
// end of [ins]
val t = ins (t, x0)
//
in
//
case+ t of cons (!p_c as R, _, _, _) => (!p_c := B; fold@ (t); t) | _ =>> t
//
end // end of [rbtree_insert]
')

#para('\

I literally implemented the above #code("rbtree_insert") by making a copy
of the previous implementation of #code("rbtree_insert") for functional
red-black trees and then properly modifying it to make it pass
typechecking. Although this process of copying-and-modifying is difficult
to be described formally, it is fairly straightforward to follow in
practice as it is almost entirely guided by the error messages received
during typechecking.

')

#para("\

Please find the entire code in this section plus some additional
code for testing #mycodelink("CHAPTER_DATAVTYPES/rbtree.dats", "on-line").
A challenging as well as rewarding exercise is for the reader to implement
an operation to delete an element from a given linear red-black tree.

")

</sect1>#comment("sect1/id=transition_from_datatypes_to_dataviewtypes")

</chapter><!--id="dataviewtypes"-->

#comment(" ****** ****** ")
#comment(" end of [main.atxt] ")

%{
implement main () = fprint_filsub (stdout_ref, "main_atxt.txt")
%}
